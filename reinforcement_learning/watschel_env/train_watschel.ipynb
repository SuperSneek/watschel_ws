{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAYY\n"
     ]
    }
   ],
   "source": [
    "from watschel_env.envs.policy_network import REINFORCE, Policy_Network\n",
    "import torch, random\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_curve(rewards_over_episodes) :\n",
    "    rewards_to_plot = rewards_over_episodes\n",
    "    df1 = pd.DataFrame(rewards_to_plot).melt()\n",
    "    df1.rename(columns={\"variable\": \"episodes\", \"value\": \"reward\"}, inplace=True)\n",
    "    sns.set(style=\"darkgrid\", context=\"talk\", palette=\"rainbow\")\n",
    "    sns.lineplot(x=\"episodes\", y=\"reward\", data=df1).set(\n",
    "        title=\"REINFORCE for WatschelWorld-v0\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Projects/watschel_ws/reinforcement_learning/watschel_env/watschel_env/envs/policy_network.py:156: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(r\"/home/jonas/Projects/watschel_ws/reinforcement_learning/ressources/watschel_policy.dict\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/jonas/Projects/watschel_ws/reinforcement_learning/ressources/watschel_policy.dict'\n",
      "Loading Model and Optimizer failed :(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:131: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(\n",
      "/home/jonas/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  gym.logger.warn(\"Casting input x to numpy array.\")\n",
      "/home/jonas/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:131: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting a numpy array, actual type: <class 'list'>\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Average Reward: -145\n",
      "Episode: 20 Average Reward: -145\n",
      "Episode: 40 Average Reward: -146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m reward_over_episodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_num_episodes):\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# gymnasium v26 requires users to set seed while resetting the environment\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     obs \u001b[38;5;241m=\u001b[39m (obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/wrappers/record_episode_statistics.py:78\u001b[0m, in \u001b[0;36mRecordEpisodeStatistics.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment using kwargs and resets the episode returns and lengths.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_start_times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, time\u001b[38;5;241m.\u001b[39mperf_counter(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_returns \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/core.py:467\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    465\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/wrappers/time_limit.py:75\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/wrappers/order_enforcing.py:61\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/gymnasium/wrappers/env_checker.py:59\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/watschel_ws/reinforcement_learning/watschel_env/watschel_env/envs/watschel_env.py:66\u001b[0m, in \u001b[0;36mWatschelWorld.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39msetInt32Param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mintparam_speedmodifier, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mstartSimulation()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_info()\n",
      "File \u001b[0;32m~/Projects/watschel_ws/reinforcement_learning/watschel_env/watschel_env/envs/watschel_env.py:40\u001b[0m, in \u001b[0;36mWatschelWorld._get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallScriptFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_joint_angles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbridge_handle\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m :  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mcallScriptFunction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_position\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbridge_handle)}\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/coppeliasim_zmqremoteapi_client/__init__.py:174\u001b[0m, in \u001b[0;36mRemoteAPIClient.getObject.<locals>.<lambda>\u001b[0;34m(func, *a)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound nondict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m v:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(ret, k, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39ma, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m v:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(ret, k, v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/coppeliasim_zmqremoteapi_client/__init__.py:137\u001b[0m, in \u001b[0;36mRemoteAPIClient.call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, args):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# Call function with specified arguments. Is reentrant\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m: func, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m: args})\n\u001b[0;32m--> 137\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reply, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m reply:\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;66;03m# We have a callback or a wait/repeat:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m reply[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_*wait*_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/coppeliasim_zmqremoteapi_client/__init__.py:119\u001b[0m, in \u001b[0;36mRemoteAPIClient._recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 119\u001b[0m     rawResp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived raw len=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rawResp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, base64=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb64(rawResp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:805\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:841\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:194\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/watschel_rl/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and wrap the environment\n",
    "env = gym.make(\"watschel_env/watschelworld-v0\")\n",
    "wrapped_env = gym.wrappers.RecordEpisodeStatistics(env, 50)  # Records episode-reward\n",
    "\n",
    "total_num_episodes = int(5e3)  # Total number of episodes\n",
    "# Observation-space of InvertedPendulum-v4 (4)\n",
    "obs_space_dims = env.observation_space[\"legs\"].shape[0] + env.env.observation_space[\"position\"].shape[0]\n",
    "# Action-space of InvertedPendulum-v4 (1)\n",
    "action_space_dims = env.action_space.shape[0]\n",
    "rewards_over_seeds = []\n",
    "\n",
    "for seed in [1, 2, 3, 5, 8]:  # Fibonacci seeds\n",
    "    # set seed\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Reinitialize agent every seed\n",
    "    agent = REINFORCE(obs_space_dims, action_space_dims)\n",
    "    reward_over_episodes = []\n",
    "\n",
    "\n",
    "    for episode in range(total_num_episodes):\n",
    "\n",
    "\n",
    "        # gymnasium v26 requires users to set seed while resetting the environment\n",
    "        obs, info = wrapped_env.reset(seed=seed)\n",
    "        obs = (obs[\"legs\"] + obs[\"position\"])\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.sample_action(obs)\n",
    "\n",
    "            # Step return type - `tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]`\n",
    "            # These represent the next observation, the reward from the step,\n",
    "            # if the episode is terminated, if the episode is truncated and\n",
    "            # additional info from the step\n",
    "            obs, reward, terminated, truncated, info = wrapped_env.step(action)\n",
    "            obs = (obs[\"legs\"] + obs[\"position\"])\n",
    "            agent.rewards.append(reward)\n",
    "\n",
    "            # End the episode when either truncated or terminated is true\n",
    "            #  - truncated: The episode duration reaches max number of timesteps\n",
    "            #  - terminated: Any of the state space values is no longer finite.\n",
    "            done = terminated or truncated\n",
    "\n",
    "        reward_over_episodes.append(wrapped_env.return_queue[-1])\n",
    "        agent.update()\n",
    "\n",
    "\n",
    "\n",
    "        if episode % 20 == 0:\n",
    "            avg_reward = int(np.mean(wrapped_env.return_queue))\n",
    "            print(\"Episode:\", episode, \"Average Reward:\", avg_reward)\n",
    "            agent.save()\n",
    "\n",
    "    rewards_over_seeds.append(reward_over_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforcement_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
